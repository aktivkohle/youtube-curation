{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## There are 7647 distinct youtube video captions texts in English and a directory containing 24 english books, some of which from the site www.gutenberg.org which are proofread. The following scripts allow similarity measures between either the captions alone or the books to be made. Initially, get it to work on a subset of the 7647..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import config\n",
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password=config.MYSQL_SERVER_PASSWORD,\n",
    "                             db='youtubeProjectDB',\n",
    "                             charset='utf8mb4', \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "\n",
    "mypath = '../textbooks'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    \n",
    "with connection.cursor() as cursor:\n",
    "                       \n",
    "            sql = \"\"\"\n",
    "            SELECT search_api.videoId, videoTitle, captionsText, wordCount, captions.id \n",
    "            FROM search_api\n",
    "            INNER JOIN captions\n",
    "            ON search_api.videoId = captions.videoId\n",
    "            WHERE captions.id \n",
    "            IN (5830, 45, 52, 54, 6195, 6198, 6203, 6208, 14525, 14523, 14518);\"\"\"            \n",
    "            cursor.execute(sql)\n",
    "            manyCaptions = cursor.fetchall()\n",
    "            videos_df = pd.read_sql(sql, connection)\n",
    "                        \n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place the captions and books into ordered dictionaries with keys which identify their contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = []\n",
    "L2 = []\n",
    "for file in onlyfiles:\n",
    "    L1.append((file ,  (open(mypath + '/' + file, 'r').read()) ))\n",
    "TextBooksDict = OrderedDict(L1)\n",
    "\n",
    "for item in manyCaptions:\n",
    "    #  L2.append((item.get('id')  ,  item.get('captionsText')))  # 'id' key is lower case!!!\n",
    "    L2.append((item.get('videoTitle')  ,  item.get('captionsText')))\n",
    "ManyCaptionsDict = OrderedDict(L2)   \n",
    "\n",
    "# Merge OrderedDict's'\n",
    "L3 = []\n",
    "for k, v in zip(ManyCaptionsDict.keys(), ManyCaptionsDict.values()):\n",
    "    L3.append((k,v))\n",
    "for k, v in zip(TextBooksDict.keys(), TextBooksDict.values()):\n",
    "    L3.append((k,v))\n",
    "UnitedOrderedDict = OrderedDict(L3)\n",
    "\n",
    "videos_df['characterCount'] = videos_df['captionsText'].map(len)\n",
    "# reorder the columns\n",
    "videos_df['charPerWord'] = videos_df.characterCount / videos_df.wordCount\n",
    "videos_df = videos_df.reindex(columns=['videoTitle','characterCount','wordCount', 'charPerWord','captionsText','id', 'videoId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use pickes to avoid rerunning the word-count cell unnecessarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "textbooks_df = pd.read_pickle('textbooksDF.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NB - this cell can take minutes to run rather load from pickle if nothing added. \n",
    "# https://chrisalbon.com/python/pandas_create_column_with_loop.html\n",
    "fileName = [k for k in TextBooksDict.keys()]\n",
    "characterCount = [len(TextBooksDict.get(k)) for k in TextBooksDict.keys()]\n",
    "wordCount = [len(nlp(TextBooksDict.get(k))) for k in TextBooksDict.keys()]\n",
    "raw_data = {'fileName' : fileName,\n",
    "            'characterCount': characterCount,\n",
    "            'wordCount':wordCount}\n",
    "textbooks_df = pd.DataFrame(raw_data, columns = ['fileName', 'characterCount', 'wordCount'])\n",
    "textbooks_df['charPerWord'] = textbooks_df.characterCount / textbooks_df.wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "textbooks_df.to_pickle('textbooksDF.pickle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### samples of both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoTitle</th>\n",
       "      <th>characterCount</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>charPerWord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL ABOUT LIVING WITH BOXER DOGS</td>\n",
       "      <td>16843</td>\n",
       "      <td>3862</td>\n",
       "      <td>4.361212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lulu the Lab - Basic dog training in Austin (5...</td>\n",
       "      <td>485</td>\n",
       "      <td>100</td>\n",
       "      <td>4.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PetSmart Puppy Training: Feeding a Puppy</td>\n",
       "      <td>2953</td>\n",
       "      <td>677</td>\n",
       "      <td>4.361891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6. Reconstruction from Compressed Representation</td>\n",
       "      <td>3448</td>\n",
       "      <td>735</td>\n",
       "      <td>4.691156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unit 6 8 Supervised vs Unsupervised Learning</td>\n",
       "      <td>2054</td>\n",
       "      <td>395</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          videoTitle  characterCount  \\\n",
       "0                   ALL ABOUT LIVING WITH BOXER DOGS           16843   \n",
       "1  Lulu the Lab - Basic dog training in Austin (5...             485   \n",
       "2           PetSmart Puppy Training: Feeding a Puppy            2953   \n",
       "3   6. Reconstruction from Compressed Representation            3448   \n",
       "4       Unit 6 8 Supervised vs Unsupervised Learning            2054   \n",
       "\n",
       "   wordCount  charPerWord  \n",
       "0       3862     4.361212  \n",
       "1        100     4.850000  \n",
       "2        677     4.361891  \n",
       "3        735     4.691156  \n",
       "4        395     5.200000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df[['videoTitle', 'characterCount', 'wordCount', 'charPerWord']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>characterCount</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>charPerWord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sheep.txt</td>\n",
       "      <td>427001</td>\n",
       "      <td>92664</td>\n",
       "      <td>4.608057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corporate Finance.txt</td>\n",
       "      <td>3141127</td>\n",
       "      <td>691207</td>\n",
       "      <td>4.544409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excel2010Advanced.txt</td>\n",
       "      <td>287867</td>\n",
       "      <td>61451</td>\n",
       "      <td>4.684497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distributedAI.txt</td>\n",
       "      <td>175861</td>\n",
       "      <td>42156</td>\n",
       "      <td>4.171672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BrianYarvinPloughmansLunch.txt</td>\n",
       "      <td>287345</td>\n",
       "      <td>65212</td>\n",
       "      <td>4.406321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fileName  characterCount  wordCount  charPerWord\n",
       "0                       sheep.txt          427001      92664     4.608057\n",
       "1           Corporate Finance.txt         3141127     691207     4.544409\n",
       "2           Excel2010Advanced.txt          287867      61451     4.684497\n",
       "3               distributedAI.txt          175861      42156     4.171672\n",
       "4  BrianYarvinPloughmansLunch.txt          287345      65212     4.406321"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbooks_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226327.125\n",
      "835.727272727\n"
     ]
    }
   ],
   "source": [
    "print (textbooks_df.wordCount.mean())\n",
    "print (videos_df.wordCount.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute one of the follwing three cells to run similarity tests between either: \n",
    "### i) Just the textbooks\n",
    "### ii) Just the video captions\n",
    "### iii) textbooks and video captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [TextBooksDict.get(key) for key in list(TextBooksDict)]\n",
    "# following two rows are used in a pretty-print thing at the bottom of the notebook\n",
    "# to put the labels back on to an otherwise unlabeled NumPy array\n",
    "row_labels = list(TextBooksDict)\n",
    "column_labels = list(TextBooksDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [ManyCaptionsDict.get(key) for key in list(ManyCaptionsDict)]\n",
    "\n",
    "row_labels = list(ManyCaptionsDict)\n",
    "column_labels = list(ManyCaptionsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [UnitedOrderedDict.get(key) for key in list(UnitedOrderedDict)]\n",
    "\n",
    "row_labels = list(UnitedOrderedDict)\n",
    "column_labels = list(UnitedOrderedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adapt the script from https://nicschrading.com/project/Intro-to-NLP-with-spaCy/ which uses the modern NLP library SpaCy to create a text cleaner and text tokenizer for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "parser = English()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "# List of symbols we don't care about\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]\n",
    "\n",
    "# Every step in a pipeline needs to be a \"transformer\". \n",
    "# Define a custom transformer to clean text using spaCy\n",
    "class CleanTextTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert text to cleaned text\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [cleanText(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "# A custom function to clean the text before sending it into the vectorizer\n",
    "def cleanText(text):\n",
    "    # get rid of newlines\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    \n",
    "    # replace twitter @mentions\n",
    "    mentionFinder = re.compile(r\"@[a-z0-9_]{1,15}\", re.IGNORECASE)\n",
    "    text = mentionFinder.sub(\"@MENTION\", text)\n",
    "    \n",
    "    # replace HTML symbols\n",
    "    text = text.replace(\"&amp;\", \"and\").replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\")\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# A custom function to tokenize the text using spaCy\n",
    "# and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def printNMostInformative(vectorizer, clf, N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    topClass1 = coefs_with_fns[:N]\n",
    "    topClass2 = coefs_with_fns[:-(N + 1):-1]\n",
    "    print(\"Class 1 best: \")\n",
    "    for feat in topClass1:\n",
    "        print(feat)\n",
    "    print(\"Class 2 best: \")\n",
    "    for feat in topClass2:\n",
    "        print(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the appropriate scikit-learn vectorizer to create a term-document matrix\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "\n",
    "The `sklearn.feature_extraction.text` submodule gathers utilities to build feature vectors from text documents.\n",
    "\n",
    "`feature_extraction.text.CountVectorizer([...])` \t**- Convert a collection of text documents to a matrix of token counts**\n",
    "\n",
    "`feature_extraction.text.HashingVectorizer([...])` \t**- Convert a collection of text documents to a matrix of token occurrences**\n",
    "\n",
    "`feature_extraction.text.TfidfTransformer([...])` \t**- Transform a count matrix to a normalized tf or tf-idf representation**\n",
    "\n",
    "`feature_extraction.text.TfidfVectorizer([...])` \t**-Convert a collection of raw documents to a matrix of TF-IDF features.**\n",
    "\n",
    "## CountVectorizer is wrong, go with TfidfVectorizer, but if this needs to be scaled to something bigger one day, test out HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))   \n",
    "# (containing the SpacY tokenizer tokenizeText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the cleaner and vectorizer in a pipeline and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the pipeline to clean, tokenize, vectorize, and classify\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipe.fit_transform(documents)   # takes 20 min with ~10 textbooks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the transformation to the term document matrix to compute similarity between all pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairwise_similarity = (p * p.T).A #  In Scipy, .A transforms a sparse matrix to a dense one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captions and books together (First 10 are captions, If it ends with .txt it is a book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL ABOUT LIVING WITH BOXER DOGS</th>\n",
       "      <th>Lulu the Lab - Basic dog training in Austin (512) 927-9443</th>\n",
       "      <th>PetSmart Puppy Training: Feeding a Puppy</th>\n",
       "      <th>6. Reconstruction from Compressed Representation</th>\n",
       "      <th>Unit 6 8 Supervised vs Unsupervised Learning</th>\n",
       "      <th>How To Socialise An Older Cat, 5 tips! PLUS: COMPETITION!</th>\n",
       "      <th>Smart and Funny Maine Coon Cat Leo Patents His Invention - Cat Toy using Drill Tutorial</th>\n",
       "      <th>My Cats Review the Licki Brush</th>\n",
       "      <th>Crispy Spicy Fried Cauliflower - Frittierte knusprige Blumenkohl - vegetarisch - Arabisch Kochen</th>\n",
       "      <th>Feuerwehrfrau kocht kinderleichten Nudelauflauf</th>\n",
       "      <th>...</th>\n",
       "      <th>Excel2007VBA.txt</th>\n",
       "      <th>chp_handbook.txt</th>\n",
       "      <th>ElectricPowerGeneration.txt</th>\n",
       "      <th>ChemicalProcessDesign.txt</th>\n",
       "      <th>EnergyOptimization.txt</th>\n",
       "      <th>InternalCombustionEngines.txt</th>\n",
       "      <th>ISLR Sixth Printing.txt</th>\n",
       "      <th>machineLearning_chapmanHall.txt</th>\n",
       "      <th>Ensemble methods - Zhou.txt</th>\n",
       "      <th>huntingDogs.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL ABOUT LIVING WITH BOXER DOGS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162420</td>\n",
       "      <td>0.111564</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.090717</td>\n",
       "      <td>0.028510</td>\n",
       "      <td>0.068924</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>0.061817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.027553</td>\n",
       "      <td>0.028639</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.399497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lulu the Lab - Basic dog training in Austin (512) 927-9443</th>\n",
       "      <td>0.162420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060075</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.020363</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.181076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PetSmart Puppy Training: Feeding a Puppy</th>\n",
       "      <td>0.111564</td>\n",
       "      <td>0.060075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028677</td>\n",
       "      <td>0.024602</td>\n",
       "      <td>0.038684</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.094051</td>\n",
       "      <td>0.029028</td>\n",
       "      <td>0.095519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059873</td>\n",
       "      <td>0.028281</td>\n",
       "      <td>0.026857</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.031976</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.031147</td>\n",
       "      <td>0.027284</td>\n",
       "      <td>0.024467</td>\n",
       "      <td>0.062205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ALL ABOUT LIVING WITH BOXER DOGS  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                            1.000000   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                          0.162420   \n",
       "PetSmart Puppy Training: Feeding a Puppy                                    0.111564   \n",
       "\n",
       "                                                    Lulu the Lab - Basic dog training in Austin (512) 927-9443  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                                             0.162420            \n",
       "Lulu the Lab - Basic dog training in Austin (51...                                           1.000000            \n",
       "PetSmart Puppy Training: Feeding a Puppy                                                     0.060075            \n",
       "\n",
       "                                                    PetSmart Puppy Training: Feeding a Puppy  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                                    0.111564   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                                  0.060075   \n",
       "PetSmart Puppy Training: Feeding a Puppy                                            1.000000   \n",
       "\n",
       "                                                    6. Reconstruction from Compressed Representation  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                                            0.023014   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                                          0.009552   \n",
       "PetSmart Puppy Training: Feeding a Puppy                                                    0.028677   \n",
       "\n",
       "                                                    Unit 6 8 Supervised vs Unsupervised Learning  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                                        0.021225   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                                      0.005042   \n",
       "PetSmart Puppy Training: Feeding a Puppy                                                0.024602   \n",
       "\n",
       "                                                    How To Socialise An Older Cat, 5 tips! PLUS: COMPETITION!  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                                             0.090717           \n",
       "Lulu the Lab - Basic dog training in Austin (51...                                           0.025828           \n",
       "PetSmart Puppy Training: Feeding a Puppy                                                     0.038684           \n",
       "\n",
       "                                                    Smart and Funny Maine Coon Cat Leo Patents His Invention - Cat Toy using Drill Tutorial  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                                             0.028510                                         \n",
       "Lulu the Lab - Basic dog training in Austin (51...                                           0.002559                                         \n",
       "PetSmart Puppy Training: Feeding a Puppy                                                     0.017653                                         \n",
       "\n",
       "                                                    My Cats Review the Licki Brush  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                          0.068924   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                        0.020363   \n",
       "PetSmart Puppy Training: Feeding a Puppy                                  0.094051   \n",
       "\n",
       "                                                    Crispy Spicy Fried Cauliflower - Frittierte knusprige Blumenkohl - vegetarisch - Arabisch Kochen  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                                             0.017389                                                  \n",
       "Lulu the Lab - Basic dog training in Austin (51...                                           0.005485                                                  \n",
       "PetSmart Puppy Training: Feeding a Puppy                                                     0.029028                                                  \n",
       "\n",
       "                                                    Feuerwehrfrau kocht kinderleichten Nudelauflauf  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                                           0.061817   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                                         0.013808   \n",
       "PetSmart Puppy Training: Feeding a Puppy                                                   0.095519   \n",
       "\n",
       "                                                         ...         \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                         ...          \n",
       "Lulu the Lab - Basic dog training in Austin (51...       ...          \n",
       "PetSmart Puppy Training: Feeding a Puppy                 ...          \n",
       "\n",
       "                                                    Excel2007VBA.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                            0.027938   \n",
       "Lulu the Lab - Basic dog training in Austin (51...          0.009829   \n",
       "PetSmart Puppy Training: Feeding a Puppy                    0.059873   \n",
       "\n",
       "                                                    chp_handbook.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                            0.022023   \n",
       "Lulu the Lab - Basic dog training in Austin (51...          0.003914   \n",
       "PetSmart Puppy Training: Feeding a Puppy                    0.028281   \n",
       "\n",
       "                                                    ElectricPowerGeneration.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                       0.027553   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                     0.006152   \n",
       "PetSmart Puppy Training: Feeding a Puppy                               0.026857   \n",
       "\n",
       "                                                    ChemicalProcessDesign.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                     0.028639   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                   0.002833   \n",
       "PetSmart Puppy Training: Feeding a Puppy                             0.039062   \n",
       "\n",
       "                                                    EnergyOptimization.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                  0.024127   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                0.005993   \n",
       "PetSmart Puppy Training: Feeding a Puppy                          0.031976   \n",
       "\n",
       "                                                    InternalCombustionEngines.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                         0.017754   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                       0.005047   \n",
       "PetSmart Puppy Training: Feeding a Puppy                                 0.016927   \n",
       "\n",
       "                                                    ISLR Sixth Printing.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                   0.028871   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                 0.013376   \n",
       "PetSmart Puppy Training: Feeding a Puppy                           0.031147   \n",
       "\n",
       "                                                    machineLearning_chapmanHall.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                           0.023511   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                         0.007113   \n",
       "PetSmart Puppy Training: Feeding a Puppy                                   0.027284   \n",
       "\n",
       "                                                    Ensemble methods - Zhou.txt  \\\n",
       "ALL ABOUT LIVING WITH BOXER DOGS                                       0.014963   \n",
       "Lulu the Lab - Basic dog training in Austin (51...                     0.010723   \n",
       "PetSmart Puppy Training: Feeding a Puppy                               0.024467   \n",
       "\n",
       "                                                    huntingDogs.txt  \n",
       "ALL ABOUT LIVING WITH BOXER DOGS                           0.399497  \n",
       "Lulu the Lab - Basic dog training in Austin (51...         0.181076  \n",
       "PetSmart Puppy Training: Feeding a Puppy                   0.062205  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9 = pd.DataFrame(pairwise_similarity, columns=column_labels, index=row_labels)\n",
    "df9.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # save the 15 minutesfromlasttime\n",
    "#np.save('pairwise_similarity_35textsAndCaptions', pairwise_similarity)   \n",
    "#np.save('35textLabels', row_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.1624195 ,  0.11156364,  0.02301434,  0.02122543,\n",
       "        0.09071699,  0.02850971,  0.06892372,  0.01738899,  0.06181667,\n",
       "        0.0854467 ,  0.1053678 ,  0.03638041,  0.02099344,  0.01741988,\n",
       "        0.04163213,  0.02922342,  0.03679229,  0.04515691,  0.17137324,\n",
       "        0.01482046,  0.02065474,  0.07567835,  0.04460489,  0.0435978 ,\n",
       "        0.02793786,  0.02202279,  0.02755284,  0.02863862,  0.0241265 ,\n",
       "        0.01775361,  0.02887078,  0.0235112 ,  0.01496311,  0.39949674])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 34, 19,  1,  2, 11,  5, 10, 22,  7,  9, 18, 23, 24, 15, 17, 12,\n",
       "       16, 31, 28,  6, 25, 27, 29, 32,  3, 26,  4, 13, 21, 30, 14,  8, 33,\n",
       "       20])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-pairwise_similarity[0]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 19,  1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-pairwise_similarity[0]).argsort()[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALL ABOUT LIVING WITH BOXER DOGS'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_labels[0]\n",
    "# http://stackoverflow.com/questions/18272160/access-multiple-elements-of-list-knowing-their-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['huntingDogs.txt', 'TheDomesticCat.txt',\n",
       "       'Lulu the Lab - Basic dog training in Austin (512) 927-9443'], \n",
       "      dtype='<U96')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(row_labels))[((-pairwise_similarity[0]).argsort()[1:4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ABOUT LIVING WITH BOXER DOGS \n",
      " ['huntingDogs.txt' 'TheDomesticCat.txt'\n",
      " 'Lulu the Lab - Basic dog training in Austin (512) 927-9443'] \n",
      "\n",
      "Lulu the Lab - Basic dog training in Austin (512) 927-9443 \n",
      " ['huntingDogs.txt' 'ALL ABOUT LIVING WITH BOXER DOGS'\n",
      " 'PetSmart Puppy Training: Feeding a Puppy'] \n",
      "\n",
      "PetSmart Puppy Training: Feeding a Puppy \n",
      " ['ALL ABOUT LIVING WITH BOXER DOGS'\n",
      " '• Kochen bei Freunden (Vlog) • (Ep. 16)'\n",
      " 'Feuerwehrfrau kocht kinderleichten Nudelauflauf'] \n",
      "\n",
      "6. Reconstruction from Compressed Representation \n",
      " ['machineLearning_chapmanHall.txt' 'DataScienceBookV3.txt' 'datastyle.txt'] \n",
      "\n",
      "Unit 6 8 Supervised vs Unsupervised Learning \n",
      " ['Ensemble methods - Zhou.txt' 'datastyle.txt' 'DataScienceBookV3.txt'] \n",
      "\n",
      "How To Socialise An Older Cat, 5 tips! PLUS: COMPETITION! \n",
      " ['TheDomesticCat.txt' 'My Cats Review the Licki Brush'\n",
      " 'DataScienceBookV3.txt'] \n",
      "\n",
      "Smart and Funny Maine Coon Cat Leo Patents His Invention - Cat Toy using Drill Tutorial \n",
      " ['How To Socialise An Older Cat, 5 tips! PLUS: COMPETITION!'\n",
      " 'TheDomesticCat.txt' 'My Cats Review the Licki Brush'] \n",
      "\n",
      "My Cats Review the Licki Brush \n",
      " ['TheDomesticCat.txt'\n",
      " 'How To Socialise An Older Cat, 5 tips! PLUS: COMPETITION!'\n",
      " 'PetSmart Puppy Training: Feeding a Puppy'] \n",
      "\n",
      "Crispy Spicy Fried Cauliflower - Frittierte knusprige Blumenkohl - vegetarisch - Arabisch Kochen \n",
      " ['BrianYarvinPloughmansLunch.txt' '• Kochen bei Freunden (Vlog) • (Ep. 16)'\n",
      " 'Feuerwehrfrau kocht kinderleichten Nudelauflauf'] \n",
      "\n",
      "Feuerwehrfrau kocht kinderleichten Nudelauflauf \n",
      " ['• Kochen bei Freunden (Vlog) • (Ep. 16)' 'BrianYarvinPloughmansLunch.txt'\n",
      " 'PetSmart Puppy Training: Feeding a Puppy'] \n",
      "\n",
      "• Kochen bei Freunden (Vlog) • (Ep. 16) \n",
      " ['Feuerwehrfrau kocht kinderleichten Nudelauflauf'\n",
      " 'BrianYarvinPloughmansLunch.txt'\n",
      " 'PetSmart Puppy Training: Feeding a Puppy'] \n",
      "\n",
      "sheep.txt \n",
      " ['louisianaBeefCattle.txt' 'TheDomesticCat.txt' 'huntingDogs.txt'] \n",
      "\n",
      "Corporate Finance.txt \n",
      " ['Contemporary Engineering Economics.txt' 'HeatingCoolingPower.txt'\n",
      " 'DataAnalysisSQL.txt'] \n",
      "\n",
      "Excel2010Advanced.txt \n",
      " ['Excel2007VBA.txt' 'DataScienceBookV3.txt' 'DataAnalysisSQL.txt'] \n",
      "\n",
      "distributedAI.txt \n",
      " ['machineLearning_chapmanHall.txt' 'EnergyOptimization.txt'\n",
      " 'DataScienceBookV3.txt'] \n",
      "\n",
      "BrianYarvinPloughmansLunch.txt \n",
      " [ 'Crispy Spicy Fried Cauliflower - Frittierte knusprige Blumenkohl - vegetarisch - Arabisch Kochen'\n",
      " 'ChemicalProcessDesign.txt' 'machineLearning_chapmanHall.txt'] \n",
      "\n",
      "HeatingCoolingPower.txt \n",
      " ['catalog_chptech_full.txt' 'ChemicalProcessDesign.txt'\n",
      " 'InternalCombustionEngines.txt'] \n",
      "\n",
      "louisianaBeefCattle.txt \n",
      " ['sheep.txt' 'TheDomesticCat.txt' 'Contemporary Engineering Economics.txt'] \n",
      "\n",
      "datastyle.txt \n",
      " ['DataScienceBookV3.txt' 'ISLR Sixth Printing.txt'\n",
      " 'machineLearning_chapmanHall.txt'] \n",
      "\n",
      "TheDomesticCat.txt \n",
      " ['How To Socialise An Older Cat, 5 tips! PLUS: COMPETITION!'\n",
      " 'My Cats Review the Licki Brush' 'sheep.txt'] \n",
      "\n",
      "catalog_chptech_full.txt \n",
      " ['HeatingCoolingPower.txt' 'InternalCombustionEngines.txt'\n",
      " 'chp_handbook.txt'] \n",
      "\n",
      "appliedStatistics.txt \n",
      " ['machineLearning_chapmanHall.txt' 'ISLR Sixth Printing.txt'\n",
      " 'EnergyOptimization.txt'] \n",
      "\n",
      "DataScienceBookV3.txt \n",
      " ['datastyle.txt' 'ISLR Sixth Printing.txt'\n",
      " 'machineLearning_chapmanHall.txt'] \n",
      "\n",
      "DataAnalysisSQL.txt \n",
      " ['DataScienceBookV3.txt' 'datastyle.txt' 'ISLR Sixth Printing.txt'] \n",
      "\n",
      "Contemporary Engineering Economics.txt \n",
      " ['Corporate Finance.txt' 'HeatingCoolingPower.txt' 'chp_handbook.txt'] \n",
      "\n",
      "Excel2007VBA.txt \n",
      " ['Excel2010Advanced.txt' 'DataScienceBookV3.txt' 'DataAnalysisSQL.txt'] \n",
      "\n",
      "chp_handbook.txt \n",
      " ['catalog_chptech_full.txt' 'HeatingCoolingPower.txt'\n",
      " 'Contemporary Engineering Economics.txt'] \n",
      "\n",
      "ElectricPowerGeneration.txt \n",
      " ['HeatingCoolingPower.txt' 'ChemicalProcessDesign.txt'\n",
      " 'EnergyOptimization.txt'] \n",
      "\n",
      "ChemicalProcessDesign.txt \n",
      " ['EnergyOptimization.txt' 'HeatingCoolingPower.txt'\n",
      " 'catalog_chptech_full.txt'] \n",
      "\n",
      "EnergyOptimization.txt \n",
      " ['ChemicalProcessDesign.txt' 'HeatingCoolingPower.txt'\n",
      " 'machineLearning_chapmanHall.txt'] \n",
      "\n",
      "InternalCombustionEngines.txt \n",
      " ['catalog_chptech_full.txt' 'HeatingCoolingPower.txt'\n",
      " 'ChemicalProcessDesign.txt'] \n",
      "\n",
      "ISLR Sixth Printing.txt \n",
      " ['machineLearning_chapmanHall.txt' 'datastyle.txt' 'DataScienceBookV3.txt'] \n",
      "\n",
      "machineLearning_chapmanHall.txt \n",
      " ['ISLR Sixth Printing.txt' 'appliedStatistics.txt' 'DataScienceBookV3.txt'] \n",
      "\n",
      "Ensemble methods - Zhou.txt \n",
      " ['machineLearning_chapmanHall.txt' 'ISLR Sixth Printing.txt'\n",
      " 'EnergyOptimization.txt'] \n",
      "\n",
      "huntingDogs.txt \n",
      " ['ALL ABOUT LIVING WITH BOXER DOGS' 'TheDomesticCat.txt'\n",
      " 'Lulu the Lab - Basic dog training in Austin (512) 927-9443'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(row_labels)):\n",
    "    print (row_labels[i], '\\n', (np.array(row_labels))[((-pairwise_similarity[i]).argsort()[1:4])], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _fantastic it's working! Similar youtube captions and texts from books seem to have in most cases found each other :)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If needed examine the contents of the pipeline before fit_transform is applied with the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"The original data as it appeared to the classifier after tokenizing, lemmatizing, stoplisting, etc\")\n",
    "\n",
    "transform = p \n",
    "\n",
    "# get the features that the vectorizer learned (its vocabulary)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "# the values from the vectorizer transformed data (each item is a row,column index with value as # times occuring in the sample, stored as a sparse matrix)\n",
    "for i in range(len(documents)):\n",
    "    s = \"\"\n",
    "    indexIntoVocab = transform.indices[transform.indptr[i]:transform.indptr[i+1]]\n",
    "    numOccurences = transform.data[transform.indptr[i]:transform.indptr[i+1]]\n",
    "    for idx, num in zip(indexIntoVocab, numOccurences):\n",
    "        s += str((vocab[idx], num))\n",
    "    print(\"Sample {}: {}\".format(i, s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
